<<<Algorithm: gradient_descent>>
iterations:
100 500 1000 5000 10000 15000 20000
[100, 500, 1000, 5000, 10000, 15000, 20000]

train_scores: 0.9351708074534161
0.7853260869565217 0.90625 0.9266304347826086 0.96875 0.9782608695652174 0.9891304347826086 0.9918478260869565
[0.7853260869565217, 0.90625, 0.9266304347826086, 0.96875, 0.9782608695652174, 0.9891304347826086, 0.9918478260869565]

train_tests: 0.9371118012422361
0.8532608695652174 0.9347826086956522 0.9510869565217391 0.9565217391304348 0.9619565217391305 0.9510869565217391 0.9510869565217391
[0.8532608695652174, 0.9347826086956522, 0.9510869565217391, 0.9565217391304348, 0.9619565217391305, 0.9510869565217391, 0.9510869565217391]

times:
0.27175540924072267 1.5495230913162232 2.366449308395386 12.641770672798156 24.669382095336914 33.38660821914673 38.3222039937973
[0.27175540924072267, 1.5495230913162232, 2.366449308395386, 12.641770672798156, 24.669382095336914, 33.38660821914673, 38.3222039937973]
